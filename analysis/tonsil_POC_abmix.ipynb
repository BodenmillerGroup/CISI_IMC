{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e18b3b54",
   "metadata": {},
   "source": [
    "# Decompression and Prediction for pre-defined U/A\n",
    "#### (Using the Tonsil dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2ab5bd",
   "metadata": {},
   "source": [
    "This script gives an example on how to read in a compressed CISI experiment, how to decompress it and how to evaluate results using a pre-defined U and A/Phi using the data from the proof-of-concept study with an antibody-mix compressing eigth to six/four channels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a183619",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab2dd3a",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22d852d",
   "metadata": {},
   "source": [
    "First we set up the script by specifying the necessary libraries, importing the functions from CISI for IMC and specifying input paths and parameters used by CISI for IMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a8c353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import anndata as ad\n",
    "from pathlib import Path\n",
    "import errno\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "# Helper fncs\n",
    "import helpers.analysis_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21ecc07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CISI\n",
    "# Configure code directory as module\n",
    "\n",
    "# Find code directory relative to our directory\n",
    "THIS_DIR = os.path.dirname('__file__')\n",
    "CODE_DIR = os.path.abspath(os.path.join(THIS_DIR, '..', 'code'))\n",
    "# Add code directory to systems paths\n",
    "sys.path.append(CODE_DIR)\n",
    "\n",
    "# Import CISI training fnc.\n",
    "from analyze_dictionary_and_compositions import analyze_U_and_A\n",
    "from decompress import decompress\n",
    "from utils import compare_results, get_observations_no_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32240fbe",
   "metadata": {},
   "source": [
    "### Specify Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64c45c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify input paths\n",
    "data_path = Path('/mnt/bb_dqbm_volume')\n",
    "training_path = Path(os.path.join(data_path,\n",
    "                                'data/Tonsil_th152/preprocessed_data/spe.h5ad'))\n",
    "\n",
    "'''\n",
    "experiment_path = Path(os.path.join(data_path,\n",
    "                                'data/20221108_TsH_LSS_cisiabmix2_179/preprocessed_data/composite_measurements.h5ad'))\n",
    "\n",
    "U_path = Path(os.path.join(data_path,\n",
    "                                'analysis/Tonsil_th179_2/gene_modules.csv'))\n",
    "A_path = Path(os.path.join(data_path,\n",
    "                                'analysis/Tonsil_th179_2/version_1.txt'))\n",
    "A_best_path = Path(os.path.join(data_path,\n",
    "                                'analysis/Tonsil_th179_2/version_best.txt'))\n",
    "\n",
    "'''\n",
    "experiment_path = Path(os.path.join(data_path,\n",
    "                                'data/20221108_TsH_LSS_cisiabmix1_179/preprocessed_data/composite_measurements.h5ad'))\n",
    "\n",
    "U_path = Path(os.path.join(data_path,\n",
    "                           'analysis/Tonsil_th179_1/gene_modules.csv'))\n",
    "A_path = Path(os.path.join(data_path,\n",
    "                           'analysis/Tonsil_th179_1/version_1.txt'))\n",
    "A_best_path = Path(os.path.join(data_path,\n",
    "                                'analysis/Tonsil_th179_1/version_best.txt'))\n",
    "\n",
    "\n",
    "## Specify output path\n",
    "# out_path = Path(os.path.join(data_path, 'analysis/Tonsil_th179_2'))\n",
    "out_path = Path(os.path.join(data_path, 'analysis/Tonsil_th179_1'))\n",
    "out_path_training = Path(os.path.join(out_path, 'training'))\n",
    "out_path_experiment = Path(os.path.join(out_path, 'experiment'))\n",
    "out_path_experiment_simulation = Path(os.path.join(out_path, 'experiment-simulation'))\n",
    "out_path_experiment_simulation_best_A = Path(os.path.join(out_path, 'experiment-simulation-best-A'))\n",
    "# Create output directory if it doesn't exist\n",
    "out_path_training.mkdir(parents=True, exist_ok=True)\n",
    "out_path_experiment.mkdir(parents=True, exist_ok=True)\n",
    "out_path_experiment_simulation.mkdir(parents=True, exist_ok=True)\n",
    "out_path_experiment_simulation_best_A.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3739b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that input files/dictionary exist\n",
    "if not helpers.analysis_utils.is_valid_file(training_path, ['.h5ad']):\n",
    "    # If file is not found, throw error\n",
    "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT),\n",
    "                            training_path)\n",
    "if not helpers.analysis_utils.is_valid_file(experiment_path, ['.h5ad']):\n",
    "    # If file is not found, throw error\n",
    "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT),\n",
    "                            experiment_path)    \n",
    "if not helpers.analysis_utils.is_valid_file(U_path, ['.csv']):\n",
    "    # If file is not found, throw error\n",
    "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT),\n",
    "                            U_path)\n",
    "if not helpers.analysis_utils.is_valid_file(A_path, ['.txt']):\n",
    "    # If file is not found, throw error\n",
    "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT),\n",
    "                            A_path)\n",
    "\n",
    "if not helpers.analysis_utils.is_valid_file(A_best_path, ['.txt']):\n",
    "    # If file is not found, throw error\n",
    "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT),\n",
    "                            A_best_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8f089e",
   "metadata": {},
   "source": [
    "### Specify parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95031793",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify parameters for CISI\n",
    "dictionary_size = 17   # 10\n",
    "normalization = 'none'\n",
    "\n",
    "# Define test rois\n",
    "test_names_training = ('20220520_TsH_th152_cisi1_002',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6f723f",
   "metadata": {},
   "source": [
    "## Read Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853c09fc",
   "metadata": {},
   "source": [
    "Next, we read in all inputs (anndata objects containing composite measurements and training data, U, A/Phi, best A predicted by parameter sweep) and make sure that the composite channels and proteins are all in the same order for U, A/Phi and anndata objects to ensure correct matrix multiplications in CISI for IMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1920fead",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in data\n",
    "# Read in SingleCellExperiment converted to anndata by cellconverter in R\n",
    "sce_training = ad.read_h5ad(training_path)\n",
    "sce_experiment = ad.read_h5ad(experiment_path)\n",
    "# Channels of interest\n",
    "channels_of_interest = sce_experiment.var_names[sce_experiment.var_names.str.contains('^CC\\d_', regex=True)]\n",
    "proteins_of_interest = sce_experiment.var_names[~sce_experiment.var_names.isin(channels_of_interest)]\n",
    "proteins_of_interest = proteins_of_interest[~proteins_of_interest.str.contains('^Ir', regex=True)]\n",
    "# Remove uninteresting proteins/channels\n",
    "sce_training = sce_training[:, proteins_of_interest.tolist()]\n",
    "\n",
    "# Read U\n",
    "U = np.genfromtxt(U_path, delimiter=',', skip_header=True,\n",
    "                         usecols=list(range(1, (dictionary_size)+1)))\n",
    "U_names = [x.decode() for x in np.genfromtxt(U_path, delimiter=',', usecols=0, skip_header=1,\n",
    "                                             dtype='S20')]\n",
    "\n",
    "# Read A\n",
    "A = np.loadtxt(A_path, skiprows=1, usecols=list(range(1, len(proteins_of_interest)+1)))\n",
    "A_names = [x.decode() for x in np.loadtxt(A_path, max_rows=1, dtype='S20')]\n",
    "A_channels = [x.decode() for x in np.loadtxt(A_path, usecols=0, skiprows=1, dtype='S20')]\n",
    "\n",
    "\n",
    "# Read best A\n",
    "A_best = np.loadtxt(A_best_path, skiprows=1, usecols=list(range(1, len(proteins_of_interest)+1)))\n",
    "A_best_names = [x.decode() for x in np.loadtxt(A_best_path, max_rows=1, dtype='S20')]\n",
    "A_best_channels = [x.decode() for x in np.loadtxt(A_best_path, usecols=0, skiprows=1, dtype='S20')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56ae614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Throw error if A and U don't have the same proteins or A has different channels than the specified channels\n",
    "## of interest\n",
    "if (all(e in U_names for e in A_names) & all(e in A_names for e in U_names) &\n",
    "   all(e in A_channels for e in channels_of_interest) & all(e in channels_of_interest for e in A_channels)):\n",
    "    U_index = [U_names.index(ind) for ind in proteins_of_interest]\n",
    "    A_index = [A_names.index(ind) for ind in proteins_of_interest]\n",
    "    A_channel_index = [A_channels.index(ind) for ind in channels_of_interest]\n",
    "    A_best_index = [A_best_names.index(ind) for ind in proteins_of_interest]\n",
    "    \n",
    "    U = U[U_index, :].copy()\n",
    "    A = A[:, A_index].copy()\n",
    "    A = A[A_channel_index, :].copy()\n",
    "    A_best = A_best[:, A_best_index].copy()\n",
    "    \n",
    "else:\n",
    "    # Throw error\n",
    "    raise ValueError(('A and U do not have the same proteins or A does ' +\n",
    "                      'not have the channels of interest.' +\n",
    "                      'Please check all files, to prevent CISI ' +\n",
    "                      'from computing wrong results.\\n' +\n",
    "                      'Proteins in U: {0}'.format(U_names) +\n",
    "                      'Proteins in A: {0}\\n'.format(A_names) +\n",
    "                      'Channels in A: {0}\\n'.format(A_channels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27137ba",
   "metadata": {},
   "source": [
    "## Predict Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa84881b",
   "metadata": {},
   "source": [
    "For the training data and the individually measured proteins in the composite experiment, we simulate composite measurements and evaluate their perfomance using the pre-defined and read in U and A/Phi. For the real experiment we also simulate composite measurements and evaluate the performance using the best A from the parameter run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "545d241b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/cisi_imc_env/lib/python3.10/site-packages/scipy/spatial/distance.py:630: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/home/ubuntu/anaconda3/envs/cisi_imc_env/lib/python3.10/site-packages/scipy/spatial/distance.py:630: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/home/ubuntu/anaconda3/envs/cisi_imc_env/lib/python3.10/site-packages/scipy/spatial/distance.py:630: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "## Predict performance of A given A,U and SCE\n",
    "# Test for training data and real experiment data\n",
    "\n",
    "(predicted_res_training, \n",
    " predicted_res_noisy_training) = analyze_U_and_A(sce_training[sce_training.obs['sample_id'].isin(test_names_training), ],\n",
    "                                                 U, [A], ['none'], out_path_training,\n",
    "                                                 norm=normalization)\n",
    "(predicted_res_experiment, \n",
    " predicted_res_noisy_experiment) = analyze_U_and_A(sce_experiment[:, sce_experiment.var.index.isin(proteins_of_interest)],\n",
    "                                                   U, [A], ['none'], out_path_experiment_simulation,\n",
    "                                                   norm=normalization)\n",
    "\n",
    "(predicted_res_experiment_best, \n",
    " predicted_res_noisy_experiment_best) = analyze_U_and_A(sce_experiment[:, sce_experiment.var.index.isin(proteins_of_interest)],\n",
    "                                                        U, [A_best], ['none'], out_path_experiment_simulation_best_A,\n",
    "                                                        norm=normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9148783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write simulated values to anndata\n",
    "y_experiment = get_observations_no_noise((sce_experiment[:, sce_experiment.var.index.isin(proteins_of_interest)].X).T,\n",
    "                                          A, normalization=normalization)\n",
    "\n",
    "## TODO: change name\n",
    "# Write simulated composite measurements from the experiment to anndata\n",
    "composite_anndata = sce_experiment[:, sce_experiment.var.index.isin(channels_of_interest)].copy()\n",
    "for k in list(composite_anndata.layers.keys()):\n",
    "    del composite_anndata.layers[k]\n",
    "    composite_anndata.X = y_experiment.T\n",
    "    composite_anndata.write(os.path.join(out_path_experiment_simulation, 'simulated_composite_measurements.h5ad'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30271258",
   "metadata": {},
   "source": [
    "## Decompression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af431055",
   "metadata": {},
   "source": [
    "In the last part we do the actual decomposition of composite measurements and evaluate their performance compared to the individually measured protein levels as is done in the above function analyze_U_and_A()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65c3610",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Decompression\n",
    "# Decompress composite channels                     \n",
    "decompressed_x = decompress((sce_experiment[:, sce_experiment.var.index.isin(channels_of_interest)].X).T, \n",
    "                            U, A)\n",
    "# Remove infinit values                   \n",
    "decompressed_x[np.isnan(decompressed_x)] = 0\n",
    "# Compute statistics\n",
    "decompression_results = compare_results((sce_experiment[:, sce_experiment.var.index.isin(proteins_of_interest)].X).T, \n",
    "                                        decompressed_x)\n",
    "d_gene = np.percentile(1 - distance.pdist(A.dot(U).T, 'correlation'), 90)\n",
    "\n",
    "# Open file to save decompression results                 \n",
    "decompression_file = open(os.path.join(out_path_experiment, 'simulation_results.txt'), 'w')\n",
    "colnames = ['version', 'Overall pearson', 'Overall spearman', 'Gene average',\n",
    "            'Sample average', 'Sample dist pearson', 'Sample dist spearman',\n",
    "            'Gene dist pearson', 'Gene dist spearman',\n",
    "            'Matrix coherence (90th ptile)']\n",
    "decompression_file.write('\\t'.join(colnames) + '\\n')                     \n",
    "decompression_file.write('\\t'.join([str(x) for x in ['']+decompression_results+[d_gene]]) + '\\n')\n",
    "decompression_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0492df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write decomposed X to anndata\n",
    "decompressed_anndata = sce_experiment[:, sce_experiment.var.index.isin(proteins_of_interest)].copy()\n",
    "for k in list(decompressed_anndata.layers.keys()):\n",
    "    del decompressed_anndata.layers[k]\n",
    "    decompressed_anndata.X = decompressed_x.T\n",
    "    decompressed_anndata.write(os.path.join(out_path_experiment, 'X_decomposed.h5ad'))\n",
    "\n",
    "# Write original X subseted to individual protein expression levels to the same place as the decomposed X\n",
    "(sce_experiment[:, sce_experiment.var.index.isin(proteins_of_interest)]).write(os.path.join(out_path_experiment, 'X_test.h5ad'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cisi_imc",
   "language": "python",
   "name": "cisi_imc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
