{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa3e7b70",
   "metadata": {},
   "source": [
    "# Single Cell Decompression Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b046f9",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "First, we import the neccessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bcfe9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import anndata as ad\n",
    "import tifffile\n",
    "from pathlib import Path\n",
    "import errno\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a151797d",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Next, we define some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53a914bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that checks that file_path is an existing file and has a certain extension\n",
    "def is_valid_file(file_path, extension):\n",
    "    file = Path(file_path)\n",
    "    if file.exists() and file.is_file() and file.suffix in extension:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "# Function that checks if directory exists and contains at least one file\n",
    "# with certain extension\n",
    "def is_valid_directory(directory_path): \n",
    "    # Checking if the directory exists \n",
    "    if os.path.exists(directory_path): \n",
    "        # Checking if the directory is empty or not\n",
    "        if any([is_valid_file(os.path.join(directory_path, f), '.tiff') \n",
    "                for f in directory_path.iterdir() if not f.name.startswith('.')]) == True:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return  False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7124f068",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "\n",
    "In the first part we specify the paths to the input files (.h5ad files created from R SpatialExperiment, TIFF files generated by the steinbock pipeline and panel metadata file) and where the outputs should be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42b81cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify input paths\n",
    "spe_path = Path('spe.h5ad')\n",
    "tiffs_path = Path('../img')\n",
    "panel_path = Path('../panel.csv')\n",
    "\n",
    "\n",
    "# Check that input files/dictionary exist\n",
    "if not is_valid_file(spe_path, ['.h5ad']):\n",
    "    # If file is not found, throw error\n",
    "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT),\n",
    "                            spe_path)\n",
    "if not is_valid_file(panel_path, ['.csv']):\n",
    "    # If file is not found, throw error\n",
    "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT),\n",
    "                            panel_path)\n",
    "if not is_valid_directory(tiffs_path):\n",
    "    # If directory is not found or doesn't contain TIFF files, throw an error\n",
    "    raise Exception('Input TIFFS path {0} directory does not exist or does\\\n",
    "    not contain any valid TIFF files.'.format(tiffs_path)) from FileNotFoundError\n",
    "    \n",
    "\n",
    "# Specify output path\n",
    "out_path = Path('../preprocessed_data')\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "out_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573b54eb",
   "metadata": {},
   "source": [
    "Next, we read in the input files for training. For this we have the Tonsil th152 dataset consisting of 5 ROIs and we read the data in once it has been processed by steinbock into segmented single cells and once using the hot pixel corrected TIFF image files directly. From this we create one numpy array of channels x cells and once numpy array containing channels vs pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b82f3e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 156121 × 43\n",
      "    obs: 'sample_id', 'ObjectNumber', 'area', 'major_axis_length', 'minor_axis_length', 'eccentricity', 'width_px', 'height_px', 'ROI'\n",
      "    var: 'channel', 'name', 'keep', 'ilastik', 'deepcell', 'Tube.Number', 'Metal', 'use_channel'\n",
      "    uns: 'X_name'\n",
      "    layers: 'exprs', 'log_exprs'\n"
     ]
    }
   ],
   "source": [
    "# Read in SpatialExperiment converted to anndata by cellconverter in R\n",
    "spe = ad.read_h5ad(spe_path)\n",
    "print(spe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9ad84d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OverloadedDict, wrapping:\n",
      "\tOrderedDict()\n",
      "With overloaded keys:\n",
      "\t['neighbors'].\n"
     ]
    }
   ],
   "source": [
    "# Read in TIFF images and flatten into one numpy array (channels x pixels)\n",
    "image_names = [f.stem for f in tiffs_path.iterdir() if not f.name.startswith('.')]\n",
    "images_unflattened = [tifffile.imread(os.path.join(tiffs_path, f)) \n",
    "                      for f in tiffs_path.iterdir() if not f.name.startswith('.')]\n",
    "images_list = [img.reshape(img.shape[0], (img.shape[1]*img.shape[2])) for img in images_unflattened]\n",
    "\n",
    "# Read in panel metadata\n",
    "images_panel = pd.read_csv(panel_path)\n",
    "\n",
    "# Create anndata from images\n",
    "# Add image intensities per pixel matrix\n",
    "images = ad.AnnData(np.transpose(np.hstack(images_list)))\n",
    "\n",
    "# Add observation and variable names\n",
    "num_pixels = [img.shape[1] for img in images_list]\n",
    "images.obs_names = [(ele + '_' + str(j)) for i, ele in enumerate(image_names) for j in range(num_pixels[i])]\n",
    "images.var_names = images_panel['name']\n",
    "\n",
    "# Add observation metadata\n",
    "images.obs = pd.DataFrame({\n",
    "    'sample_id': [ele for i, ele in enumerate(image_names) for j in range(num_pixels[i])],\n",
    "    'ObjectNumber': [j for i, ele in enumerate(image_names) for j in range(num_pixels[i])],\n",
    "    'ROI': [ele.replace('20220520_TsH_th152_cisi1_00', '') for i, ele in enumerate(image_names) \n",
    "            for j in range(num_pixels[i])]\n",
    "})\n",
    "images.obs.index = images.obs['sample_id'].tolist()\n",
    "\n",
    "# Add panel data as variable metadata\n",
    "images.var = images_panel\n",
    "images.var.index = images.var['name'].tolist()\n",
    "print(images)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cisi_imc",
   "language": "python",
   "name": "cisi_imc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
