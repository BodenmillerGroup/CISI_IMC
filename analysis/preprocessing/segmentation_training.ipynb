{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa3e7b70",
   "metadata": {},
   "source": [
    "# Single Cell Decompression Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b046f9",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "First, we import the neccessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bcfe9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import anndata as ad\n",
    "from pathlib import Path\n",
    "import errno\n",
    "import os\n",
    "# import numpy as np\n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a151797d",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Next, we import some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53a914bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7124f068",
   "metadata": {},
   "source": [
    "## Inputs\n",
    "\n",
    "In the first part we specify the paths to the input files (.h5ad files created from R SpatialExperiment, TIFF files generated by the steinbock pipeline and panel metadata file) and where the outputs should be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42b81cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify input paths\n",
    "training_data_path = Path('/mnt/bb_dqbm_volume/data/Tonsil_th152')\n",
    "spe_path = Path(os.path.join(training_data_path, 'preprocessed_data/spe.h5ad'))\n",
    "tiffs_path = Path(os.path.join(training_data_path, 'steinbock/img'))\n",
    "panel_path = Path(os.path.join(training_data_path, 'steinbock/panel.csv'))\n",
    "\n",
    "# Specify output path\n",
    "out_path = Path(os.path.join(training_data_path, 'training'))\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "out_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aefbb90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that input files/dictionary exist\n",
    "if not preprocessing_utils.is_valid_file(spe_path, ['.h5ad']):\n",
    "    # If file is not found, throw error\n",
    "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT),\n",
    "                            spe_path)\n",
    "if not preprocessing_utils.is_valid_file(panel_path, ['.csv']):\n",
    "    # If file is not found, throw error\n",
    "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT),\n",
    "                            panel_path)\n",
    "if not preprocessing_utils.is_valid_directory(tiffs_path):\n",
    "    # If directory is not found or doesn't contain TIFF files, throw an error\n",
    "    raise Exception('Input TIFFS path {0} directory does not exist or does\\\n",
    "    not contain any valid TIFF files.'.format(tiffs_path)) from FileNotFoundError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573b54eb",
   "metadata": {},
   "source": [
    "Next, we read in the input files for training. For this we have the Tonsil th152 dataset consisting of 5 ROIs and we read the data in once it has been processed by steinbock into segmented single cells and once using the hot pixel corrected TIFF image files directly. From this we create one numpy array of channels x cells and one numpy array containing channels vs pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b82f3e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 162624 × 43\n",
      "    obs: 'sample_id', 'ObjectNumber', 'area', 'major_axis_length', 'minor_axis_length', 'eccentricity', 'width_px', 'height_px', 'ROI'\n",
      "    var: 'channel', 'name', 'keep', 'ilastik', 'deepcell', 'Tube.Number', 'Metal', 'use_channel'\n",
      "    uns: 'X_name'\n",
      "    layers: 'exprs', 'log_exprs'\n"
     ]
    }
   ],
   "source": [
    "# Read in SpatialExperiment converted to anndata by cellconverter in R\n",
    "spe = ad.read_h5ad(spe_path)\n",
    "print(spe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ad84d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 9250000 × 43\n",
      "    obs: 'sample_id', 'ObjectNumber', 'ROI'\n",
      "    var: 'channel', 'name', 'keep', 'ilastik', 'deepcell', 'Tube Number', 'Metal'\n"
     ]
    }
   ],
   "source": [
    "images = preprocessing_utils.anndata_from_tiff(tiffs_path, panel_path)\n",
    "print(images)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cisi_imc",
   "language": "python",
   "name": "cisi_imc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
