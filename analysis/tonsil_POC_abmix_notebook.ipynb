{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e987f82c",
   "metadata": {},
   "source": [
    "# Example Script for Decompression and Prediction for pre-defined U/A\n",
    "#### (Using the Tonsil dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2da23d8",
   "metadata": {},
   "source": [
    "This script gives an example on how to read in a compressed CISI experiment, how to decompress it and how to evaluate results using a pre-defined U and A/Phi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711be3cf",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c916e5",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b72f944",
   "metadata": {},
   "source": [
    "First we set up the script by specifying the necessary libraries, importing the functions from CISI for IMC and specifying input paths and parameters used by CISI for IMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a692dbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import anndata as ad\n",
    "from pathlib import Path\n",
    "import errno\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Helper fncs\n",
    "import helpers.analysis_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be2f094",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CISI\n",
    "# Configure code directory as module\n",
    "\n",
    "# Find code directory relative to our directory\n",
    "THIS_DIR = os.path.dirname('__file__')\n",
    "CODE_DIR = os.path.abspath(os.path.join(THIS_DIR, '..', 'code'))\n",
    "# Add code directory to systems paths\n",
    "sys.path.append(CODE_DIR)\n",
    "\n",
    "# Import CISI training fnc.\n",
    "from analyze_dictionary_and_compositions import analyze_U_and_A\n",
    "from decompress import decompress\n",
    "from utils import compare_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198ca36b",
   "metadata": {},
   "source": [
    "### Specify Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86abbe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify input paths\n",
    "data_path = Path('/mnt/bb_dqbm_volume')\n",
    "training_path = Path(os.path.join(data_path,\n",
    "                                'data/Tonsil_th152/preprocessed_data/spe.h5ad'))\n",
    "## TODO: Change!!!\n",
    "experiment_path = Path(os.path.join(data_path,\n",
    "                                '......'))\n",
    "\n",
    "U_path = Path(os.path.join(data_path,\n",
    "                                'analysis/.../experiment/proof_of_concept_fixed_A/gene_modules.csv'))\n",
    "A_path = Path(os.path.join(data_path,\n",
    "                                'analysis/.../experiment/proof_of_concept_fixed_A/version_1.txt'))\n",
    "\n",
    "\n",
    "## Specify output path\n",
    "out_path_training = Path(os.path.join(data_path, 'analysis/.../experiment/proof_of_concept_fixed_A/training'))\n",
    "out_path_experiment = Path(os.path.join(data_path, 'analysis/.../experiment/proof_of_concept_fixed_A/experiment'))\n",
    "out_path_experiment_simulation = Path(os.path.join(data_path, 'analysis/.../experiment/proof_of_concept_fixed_A/experiment-simulation'))\n",
    "# Create output directory if it doesn't exist\n",
    "out_path_training.mkdir(parents=True, exist_ok=True)\n",
    "out_path_experiment.mkdir(parents=True, exist_ok=True)\n",
    "out_path_experiment_simulation.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36fdd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that input files/dictionary exist\n",
    "if not helpers.analysis_utils.is_valid_file(training_path, ['.h5ad']):\n",
    "    # If file is not found, throw error\n",
    "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT),\n",
    "                            training_path)\n",
    "if not helpers.analysis_utils.is_valid_file(experiment_path, ['.h5ad']):\n",
    "    # If file is not found, throw error\n",
    "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT),\n",
    "                            experiment_path)    \n",
    "if not helpers.analysis_utils.is_valid_file(U_path, ['.csv']):\n",
    "    # If file is not found, throw error\n",
    "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT),\n",
    "                            U_path)\n",
    "if not helpers.analysis_utils.is_valid_file(A_path, ['.txt']):\n",
    "    # If file is not found, throw error\n",
    "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT),\n",
    "                            A_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e06e772",
   "metadata": {},
   "source": [
    "### Specify parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb0099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify parameters for CISI\n",
    "dictionary_size = 20\n",
    "normalization = 'none'\n",
    "\n",
    "# Define test rois\n",
    "test_names_training = ('',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4701b1",
   "metadata": {},
   "source": [
    "## Read Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcefc95d",
   "metadata": {},
   "source": [
    "Next, we read in all inputs (anndata objects containing composite measurements and training data, U, A/Phi) and make sure that the composite channels and proteins are all in the same order for U, A/Phi and anndata objects to ensure correct matrix multiplications in CISI for IMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfec8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in data\n",
    "# Read in SingleCellExperiment converted to anndata by cellconverter in R\n",
    "sce_training = ad.read_h5ad(training_path)\n",
    "sce_experiment = ad.read_h5ad(experiment_path)\n",
    "# Channels of interest\n",
    "proteins_of_interest = sce_experiment.var_names.str.contains('CC\\d_', regex=True)\n",
    "channels_of_interest = sce_experiment.var_names[~sce_experiment.var_names.str.isin(proteins_of_interest)]\n",
    "# Remove uninteresting proteins/channels\n",
    "sce_training = sce_training[:, sce_training.var.index.isin(proteins_of_interest)]\n",
    "\n",
    "# Read U\n",
    "U = np.genfromtxt(U_path, delimiter=',', skip_header=True,\n",
    "                         usecols=list(range(1, (dictionary_size)+1)))\n",
    "U_names = [x.decode() for x in np.genfromtxt(U_path, delimiter=',', usecols=0, skip_header=1,\n",
    "                                             dtype='S20')]\n",
    "\n",
    "# Read A\n",
    "A = np.loadtxt(A_path, skiprows=1, usecols=list(range(2, len(proteins_of_interest)+2)))\n",
    "A_names = [x.decode() for x in np.loadtxt(A_path, max_rows=1, dtype='S20')]\n",
    "A_channels = [x.decode() for x in np.loadtxt(A_path, usecols=1, dtype='S20')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36270e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Throw error if A and U don't have the same proteins or A has different channels than the specified channels\n",
    "## of interest\n",
    "if (all(e in U_names for e in A_names) & all(e in A_names for e in U_names) &\n",
    "   all(e in A_channels for e in channels_of_interest) & all(e in channels_of_interest for e in A_channels)):\n",
    "    U_index = [U_names.index(ind) for ind in proteins_of_interest]\n",
    "    A_index = [A_names.index(ind) for ind in proteins_of_interest]\n",
    "    A_channel_index = [A_channels.index(ind) for ind in channels_of_interest]\n",
    "    \n",
    "    U = U[U_index, :]\n",
    "    A = A[A_index, :]\n",
    "    A = A[:, A_channel_index]\n",
    "    \n",
    "else:\n",
    "    # Throw error\n",
    "    raise ValueError(('A and U do not have the same proteins or A does ' +\n",
    "                      'not have the channels of interest.' +\n",
    "                      'Please check all files, to prevent CISI ' +\n",
    "                      'from computing wrong results.\\n' +\n",
    "                      'Proteins in U: {0}'.format(U_names) +\n",
    "                      'Proteins in A: {0}\\n'.format(A_names) +\n",
    "                      'Channels in A: {0}\\n'.format(A_channels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c08b08",
   "metadata": {},
   "source": [
    "## Predict Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ee6c32",
   "metadata": {},
   "source": [
    "For the training data and the individually measured proteins in the composite experiment, we simulate composite measuremnts and evaluate their perfomance using the pre-defined and read in U an A/Phi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274dc4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict performance of A given A,U and SCE\n",
    "# Test for training data and real experiment data\n",
    "(predicted_res_training, \n",
    " predicted_res_noisy_training) = analyze_U_and_A(sce_training[sce_training.obs.index.isin(test_names_training), ],\n",
    "                                                 U, [A], ['none'], out_path_training,\n",
    "                                                 None, norm=normalization)\n",
    "(predicted_res_training, \n",
    " predicted_res_noisy_training) = analyze_U_and_A(sce_experiment[:, sce_experiment.var.index.isin(proteins_of_interest)],\n",
    "                                                 U, [A], ['none'], out_path_experiment_simulation,\n",
    "                                                 None, norm=normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a89312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write simulated values to anndata\n",
    "y_experiment = get_observations((sce_experiment[:, sce_experiment.var.index.isin(proteins_of_interest)].X).T,\n",
    "                                A, normalization=normalization)\n",
    "\n",
    "## TODO: change name\n",
    "# Write simulated composite measurements from the experiment to anndata\n",
    "composite_anndata = sce_experiment[:, sce_experiment.var.index.isin(channels_of_interest)].copy()\n",
    "for k in list(composite_anndata.layers.keys()):\n",
    "    del composite_anndata.layers[k]\n",
    "    composite_anndata.X = y_experiment.T\n",
    "    composite_anndata.write(os.path.join(out_path_experiment, 'simulated_composite_measurements.h5ad'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7994282d",
   "metadata": {},
   "source": [
    "## Decompression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82756729",
   "metadata": {},
   "source": [
    "In the last part we do the actual decomposition of composite measurements and evaluate their performance compared to the individually measured protein levels as is done in the above function analyze_U_and_A()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b773222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Decompression\n",
    "# Decompress composite channels                     \n",
    "decompressed_x = decompress((sce_experiment[:, sce_experiment.var.index.isin(channels_of_interest)].X).T, \n",
    "                            U, A)\n",
    "# Remove infinit values                   \n",
    "decompressed_x[np.isnan(decompressed_x)] = 0\n",
    "# Compute statistics\n",
    "decompression_results = compare_results((sce_experiment[:, sce_experiment.var.index.isin(proteins_of_interest)].X).T, \n",
    "                                        decompressed_x)\n",
    "d_gene = np.percentile(1 - distance.pdist(A.dot(U).T, 'correlation'), 90)\n",
    "\n",
    "# Open file to save decompression results                 \n",
    "decompression_file = open(os.path.join(out_path_experiment, 'simulation_results.txt'), 'w')\n",
    "colnames = ['version', 'Overall pearson', 'Overall spearman', 'Gene average',\n",
    "            'Sample average', 'Sample dist pearson', 'Sample dist spearman',\n",
    "            'Gene dist pearson', 'Gene dist spearman',\n",
    "            'Matrix coherence (90th ptile)']\n",
    "decompression_file.write('\\t'.join(colnames) + '\\n')                     \n",
    "decompression_file.write('\\t'.join([str(x) for x in ['']+decompression_results+[d_gene]]) + '\\n')\n",
    "decompression_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371802f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write decomposed X to anndata\n",
    "decompressed_anndata = sce_experiment[:, sce_experiment.var.index.isin(proteins_of_interest)].copy()\n",
    "for k in list(decompressed_anndata.layers.keys()):\n",
    "    del decompressed_anndata.layers[k]\n",
    "    decompressed_anndata.X = decompressed_x.T\n",
    "    decompressed_anndata.write(os.path.join(out_path_experiment, 'X_decomposed.h5ad'))\n",
    "\n",
    "# Write original X subseted to individual protein expression levels to the same place as the decomposed X\n",
    "(sce_experiment[:, sce_experiment.var.index.isin(proteins_of_interest)]).write(os.path.join(out_path_experiment, 'X_test.h5ad'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cisi_imc",
   "language": "python",
   "name": "cisi_imc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
