# Questions

## Overall
[ ] Why do the normalization on X before training?
[ ] In W decode, why is k-sparsity not enforced (instead lda2/10 is used)?
[ ] In decode() fncs., why lda2 * matrix norm for lambda1?
[ ] Why is training not evaluated on binarised phi/A ?


## Small Team
[ ] Should we look at differences of markers, or even differences in pos/neg classes?
[ ] In simulated X, there are very neg values, does that make sense? Should we put them to 0?
[ ] What is a good marker to analyse resulting X?
