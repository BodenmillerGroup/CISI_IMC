{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Home","text":"<p>     CISI for IMC Data Overview   </p>"},{"location":"index.html#about-the-project","title":"About The Project","text":"<p>This projects adapts the code from the paper \u201cCompressed sensing for highly efficient imaging transcriptomics.\u201d published in 2021 in Nature biotechnology by Cleary, Brian et al. to IMC data.  The core idea of the paper is to use compressed sensing to recover individual protein expression levels from composite measurements (e.g. using the same channel/metal-isotop to measure multiple proteins). The advantage of this is that less channels are needed  to measure the same amount of proteins as in a normal IMC run.  For more information on the steps of CISI for IMC and how it works, go to Usage.</p> <p>(back to top)</p>"},{"location":"index.html#built-with","title":"Built With","text":"<ul> <li>conda</li> <li>renv</li> <li>snakemake</li> </ul> <p>(back to top)</p>"},{"location":"index.html#getting-started","title":"Getting Started","text":"<p>This project contains the code to run CISI on IMC data and to run a parameter sweep useful for the setup of a composite experiment.  (All the scripts used to analysis the code are present in analysis/ and the resulting .html files in results/reports or available on the website)</p> <p>To get a local copy up and running follow these simple example steps.</p>"},{"location":"index.html#prerequisites","title":"Prerequisites","text":"<p>To install the environment with all the necessary python packages to run the CISI code and the snakemake parameter sweep you need to download conda.</p> <ul> <li>conda</li> </ul> <p>(back to top)</p>"},{"location":"index.html#installation","title":"Installation","text":"<ol> <li> <p>Clone the neccesary folders in the repo.    <code>sh    git clone --depth 1 --no-checkout https://github.com/BodenmillerGroup/CISI_IMC.git    cd CISI_IMC    git sparse-checkout set code analysis/parameter_sweep    git checkout</code></p> </li> <li> <p>For downloading all the packages into a conda environment, follow instructions    'i.'. If the CISI code is only accessed via the parameter sweep, there is the    option of installing a conda environment only containing snakemake and then    running the Snakefile for the parameter sweep using the --use-conda parameter.    For this, follow option 'ii.'</p> <ol> <li>Create cisi_imc_env conda environment.    <code>sh    conda env create -f analysis/parameter_sweep/envs/cisi_imc_env.yml    conda activate cisi_imc_env</code></li> <li>Create conda environment only containing snakemake.    <code>sh    conda create -n snakemake_env -c bioconda snakemake=7.17.1    conda activate snakemake_env</code> Warning    When running the parameter-sweep, add parameters <code>--use-conda --conda-frontend conda</code>    to the snakemake call.</li> </ol> </li> </ol> <p>(back to top)</p>"},{"location":"index.html#usage","title":"Usage","text":""},{"location":"index.html#cisi-for-imc","title":"CISI for IMC","text":"<p>As an input, CISI expects an anndata object containing an expression matrix with dimensions: cells x proteins. For this steinbock can be used to segment the IMC data, and the results can then be read into an R SingleCellExperiment please refer to IMCDataAnalysis. To convert the subsequent SingleCellExperiment to an anndata object the function writeH5AD() from zellkonverter can be used.</p> <p>The anndata object is used for training, validation and testing (split according to set parameters). Additionally, there are a lot more parameters that can be set. The most important parameters are listed underneath with an explanation of their function. For a more complete list of parameters, please refer to the code of the function train_dictionary_and_compositions.py.</p> <p>The main function is the train_U_and_A() function, which takes the anndata object and computes a dictionary U, a experiment design matrix A/Phi and test statistics from simulated data using part of the training data kept solely for testing purposes.</p> <pre><code>(training_res, training_res_no_noise,\nU_best, Phi_best, X_test) = train_U_and_A(anndata_object,   \n                                          outpath,\n                                          split_by='roi',  \n                                          k_cv=4,\n                                          test_set=('name_of_test_rois'),\n                                          lda1=3,\n                                          normalization='paper_norm',\n                                          d=80,\n                                          nmeasurements=10,\n                                          maxcomposition=3,\n                                          save='no_noise',\n                                          analysis_normalization=True,\n                                          best_A_method='mean')\n</code></pre> <ul> <li>X_input: anndata object containing numpy array X (cells x proteins)                Will be divided into: training, validate and test set</li> <li>outpath: Specify where output files should be saved to (used in all fnc)</li> <li>split_by: either split by 'roi' or 'percentage' (default: 'roi')</li> <li>k_cv: number k cross-validations (default: 4)             if split_by='roi, k_cv needs to be smaller and a multiple of the             number of rois (not including the test roi)</li> <li>test_set: tuple of rois used as test sets with the same names as in                 the anndata object column sample_id                 (if split_by='roi', then test_set must be set and test_size                 can't be used)</li> <li>lda1: (in mode 1) the number of nonzeros per column in W, also called sparsity (k)</li> <li>normalization: How data is normalized before running smaf (default: paper_norm)                      Options: paper_norm (normalization used in paper, protein-wise),                      min_max_norm (protein-wise) or none (from initial analysis                      recommended)</li> <li>d: the number of features (columns) in the dictionary U</li> <li>nmeasurements: number of channels (# rows of A) (default: 10)</li> <li>maxcomposition: maximum times each gene is represented (mode G),                       or max genes per composition (mode M)                       (default: 3)</li> <li>analysis_normalization: If true then normalization is used before simulating                               decomposed data and is compared to true data normalized                               the same way (default: True)</li> <li>best_A_method: Method to evaluate best A/Phi                      'min', best A chosen according to highest worst performing                             protein measured by protein-wise pearson correlation                      'mean', best A chosen according to highest mean protein-wise                              pearson correlation (default)</li> <li>save: Which decomposed X is saved.             Either the X decomposed from noisy simulated data or simulated data             without noise (default: no_noise)</li> </ul> <p>A more comprehensive example script can be found here.</p> <p>This function will create in the specified output path several files. It creates two files with result statistics from simulated data once adding noise and once without any noise (simulation_results.txt, no_noise_simulation_results.txt), the decomposed anndata object from simulated data from either noisy or without noise simulation as specified by the user (X_simulated_0.h5ad), the ground truth anndata object subsetted to the test set, e.g. the same cells as in the decomposed simulated anndata object (X_test.h5ad ), the computed dictionary U (gene_modules.csv), the experiment design matrix A (version_*.txt), and two other files, which could be used to correct decomposed expression values (conditional_probability.csv, correlations.csv has not been tested yet).</p> <p>The train_U_and_A() calls on three functions: smaf() to compute the dictionary U, compute_A() to compute the best experiment design matrix and analyze_U_and_A() to analyze the results. They can all be called individually as well.</p> <p>To decompress composite IMC data, the function decompress() can be used. The most important parameters are mentioned underneath. For more parameter options, refer to the code directly.</p> <pre><code>X_decompressed = decompress(y, U, phi)\n</code></pre> <ul> <li>y: np.array containing composite measurements (channels x cells)</li> <li>U: dictionary from CISI training</li> <li>phi: experiment design matrix A/Phi from CISI training</li> </ul> <p>Warning Be sure to have proteins/channels in y, U and phi in the same order, otherwise the matrix multiplications in CISI will lead to wrong results.</p> <p>(back to top)</p>"},{"location":"index.html#parameter-sweep","title":"Parameter Sweep","text":"<p>The parameter sweep is build using snakemake. It sweeps the parameters 'k' (sparsity), 'd' (dictionary size) and 'm' (number of measurements/channels to compress proteins into) for the given ranges. For all these runs, the most important default parameters ('split_by', 'k_cv', 'test_names', 'normalization' , 'maxItr', 'maxcomposition', 'save', 'analysis_normalization', 'best_A_method'), as well as the subset of proteins of interest (which will be compressed) in the anndata object can be set. Additionally, some input and output paths can be specified.</p> <p>Therefore, before running the parameter sweep a config yaml file needs to be created. For this use one of the example config in the analysis/parameter_sweep folder and adjust the parameters accordingly.</p> <p>The parameter sweep can then be deployed from the parameter_sweep folder using:</p> <pre><code>snakemake --cores &lt;NUMBER_OF_CORES&gt; --configfile &lt;YOUR_CONFIG&gt;.json --keep-going\n</code></pre> <p>Or if using a conda environment only containing snakemake with the flags --use-conda --conda-frontend conda.</p> <pre><code>snakemake --cores &lt;NUMBER_OF_CORES&gt; --use-conda --conda-frontend conda --configfile &lt;YOUR_CONFIG&gt;.json --keep-going\n</code></pre> <p>This will create all the outputs from CISI's training function into the specified output folder for each parameter combination, a summary .html report in the specified reports path as well as an automatic snakemake report containing additional snakemake statistics and configurations in the same folder.</p> <p>Note For more information on available flags to run snakemake, refer to command line interface snakemake.</p> <p>(back to top)</p>"},{"location":"index.html#license","title":"License","text":"<p>Distributed under the MIT License. See <code>LICENSE</code> for more information.</p> <p>(back to top)</p>"},{"location":"index.html#contact","title":"Contact","text":"<p>Leonor Schubert Santana - leonors@student.ethz.ch</p> <p>Project Link: https://github.com/BodenmillerGroup/CISI_IMC</p> <p>(back to top)</p>"},{"location":"index.html#acknowledgments","title":"Acknowledgments","text":"<ul> <li>Prof. Dr. Bernd Bodenmiller</li> <li>Dr. Nils Eling</li> <li>Tsuyoshi Hosogane</li> </ul> <p>(back to top)</p>"}]}